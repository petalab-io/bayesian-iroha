[
  {
    "objectID": "notebooks/01_web_performance/roi_decision.html",
    "href": "notebooks/01_web_performance/roi_decision.html",
    "title": "エグゼクティブサマリー",
    "section": "",
    "text": "【分析の背景】 サイト全体の平均LCP改善という表面的な指標に隠れた、決済ページ等の重要ページにおけるパフォーマンス改悪がビジネスに与える損失リスクを評価しました。本分析では、PyMC v5を用いた階層ベイズモデルに加え、ビジネス前提（売上感度）の不確実性を加味した「感度分析」を実行し、意思決定の妥当性を検証しています。\n【主要な発見】 * 期待純利益: Top/Detailページの改善効果により、全体では約 8,210万円 の大幅な増収が期待値として算出されました。 * 収益化確率（勝率）: しかし、全体の収益がプラスになる確率は 65.1% に留まり、約3回に1回は赤字になる という不安定な状態です。 * 潜在的リスクの特定: 最大の懸念点は「決済ページ（Checkout）」です。このページ単体では 77.4% の確率で1万円以上の損失が発生 しており、Topページの稼いだ利益を食いつぶす明確な「出血点」となっています。\n【最終アクション】 「条件付きリリース」 を推奨します。全体を一括リリースすることは、Checkoutページのリスク（勝率65%）が高すぎるため却下とします。 リスクの低い Top/Detail ページの改善のみを部分的にリリース し、Checkout ページに関しては実装をロールバックまたは修正した後、再検証を行うべきです。\n\nimport numpy as np\nimport pandas as pd\nimport pymc as pm\nimport arviz as az\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport japanize_matplotlib\n\n/home/peta/petaLab/bayesian-iroha/.venv/lib/python3.11/site-packages/arviz/__init__.py:39: FutureWarning: \nArviZ is undergoing a major refactor to improve flexibility and extensibility while maintaining a user-friendly interface.\nSome upcoming changes may be backward incompatible.\nFor details and migration guidance, visit: https://python.arviz.org/en/latest/user_guide/migration_guide.html\n  warn(\n\n\n\n# カラー定義\nCOLOR_PURPLE = \"#9B5DE5\"  # 事後分布・HDI\nCOLOR_YELLOW = \"#F9C74F\"  # ROPE領域\nCOLOR_GREEN  = \"#06D6A0\"  # 改善判定\nCOLOR_RED    = \"#EF476F\"  # 悪化判定\nCOLOR_GRAY   = \"#8D99AE\"  # 等価判定\n\n# 1. Matplotlibのデフォルトカラーサイクルを変更\nfrom cycler import cycler\nplt.rcParams['axes.prop_cycle'] = cycler(color=[COLOR_PURPLE, COLOR_YELLOW, COLOR_GREEN, COLOR_RED, COLOR_GRAY])\n\n# 2. Seabornのスタイル設定\nsns.set_style(\"whitegrid\")\nsns.set_palette([COLOR_PURPLE, COLOR_YELLOW, COLOR_GREEN, COLOR_RED, COLOR_GRAY])\n\n\nprint(f\"PyMC version: {pm.__version__}\")\n\n# 再現性の確保\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\n\nPyMC version: 5.26.1\n\n\n\n# --- 1. Data の生成 (N=20 小規模Data) ---\ndef generate_weighted_scenario_data(n_per_page=20):\n    \"\"\"\n    Top Page 改善、Checkout page 悪化の Trap-data 生成\n    \"\"\"\n    pages = [\"Top\", \"Detail\", \"Contract\", \"Checkout\"]\n\n    scenario = {\n        'Top': (3000, 2500),  # 改善（良）\n        'Detail': (2800, 2600),  # （微良）\n        'Contract': (3500, 3550),  # 変化なし(微増)\n        'Checkout': (3000, 4000)  #  悪化　★ここが罠\n    }\n\n    data = []\n    for page in pages:\n        mu_pre, mu_post = scenario[page]\n\n        # Pre (対数正規分布)\n        lcp_pre = rng.lognormal(mean=np.log(mu_pre), sigma=0.4, size=n_per_page)\n        data.extend([{\"page\": page, \"group\": \"pre\", \"lcp\": val} for val in lcp_pre])\n\n        # Post (対数正規分布)\n        lcp_post = rng.lognormal(mean=np.log(mu_post), sigma=0.4, size=n_per_page)\n        data.extend([{\"page\": page, \"group\": \"post\", \"lcp\": val} for val in lcp_post])\n\n    return pd.DataFrame(data)\n\n\ndf = generate_weighted_scenario_data(n_per_page=20)\n\n\n# 基本統計量の確認\nprint(\"--- 基本統計量（Group × Page） ---\")\n\ndf.groupby(\"group\").agg({\"lcp\": \"mean\"})\n\n--- 基本統計量（Group × Page） ---\n\n\n\n\n\n\n\n\n\nlcp\n\n\ngroup\n\n\n\n\n\npost\n3196.734803\n\n\npre\n3225.695790\n\n\n\n\n\n\n\n単純に df.groupby(\"group\").agg({\"lcp\": \"mean\"}) を見ると、Sample数が均等なため - Pre: 3225ms -&gt; Post: 3196ms\nと、全体として大きな変化はありません。\n\ndf.groupby([\"page\", \"group\"]).agg({\"lcp\": \"mean\"}).unstack()  # 確認\n\n# unstack() は、MultiIndex（重層的なインデックス）を持つ Series や DataFrame のインデックスの最下層を、カラム（列）へと展開（ピボット）する効果があります。\n# このコードの場合、groupby([\"page\", \"group\"]) によってインデックスが page と group の二段構えになりますが、\n# .unstack() を付けることで、group（pre/Post）が横に並び、ページごとの比較がしやすくなります。\n\n\n\n\n\n\n\n\nlcp\n\n\ngroup\npost\npre\n\n\npage\n\n\n\n\n\n\nCheckout\n3840.892359\n3570.660555\n\n\nContract\n3587.029423\n3158.051664\n\n\nDetail\n2607.372864\n3050.224780\n\n\nTop\n2751.644568\n3123.846159\n\n\n\n\n\n\n\nCheckout を見ると明確に悪化しています。\n\n# 分布の可視化\nfig, axes = plt.subplots(2, 2, figsize=(18, 9))\nax_flat = axes.flatten()\n\nfor i, page in enumerate(df[\"page\"].unique()):\n    sns.histplot(data=df[df[\"page\"] == page], x=\"lcp\", hue=\"group\", kde=True, log_scale=True, ax=ax_flat[i])\n    ax_flat[i].set_title(f\"LCP {page}\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nこの可視化において注目すべき点は、「平均値の罠」が視覚的に表現されていることです。\n\nTopページとDetailページ（改善傾向）: 青色（Pre）に比べて、オレンジ色（Post）の分布が左側（LCPが小さい、つまり高速な方向）にシフトしていることが見て取れます。特にTopページでは、ヒストグラムの山が明確に左へ移動しており、パフォーマンス改善の恩恵を最も受けていることがわかります。\nContractページ（変化なし）: PreとPostの分布がほぼ重なっており、施策による影響がほとんど見られません。\nCheckoutページ（改悪傾向：重要）: ここが本分析の「罠」となる部分です。他のページとは逆に、オレンジ色（Post）の分布が右側（LCPが大きい、つまり低速な方向）へシフトし、裾野も広がっています。これは、決済画面において明確なパフォーマンス低下が発生していることを示唆しています。\n\n\n技術的補足と直感的な説明\n\n対数正規分布と対数スケール (Log Scale) 【定義】: LCPのような待ち時間データは、下限が0で右側に長い裾を持つ性質があるため、通常は対数正規分布に従います。このプロットでは log_scale=True を使用することで、歪んだデータを正規分布に近い形に変換し、中心傾向（最頻値や中央値）のズレを視覚的に比較しやすくしています。 【直感】: 待ち時間のデータは、「すごく遅い人」が一部混じるため、単純な平均をとると実態を見誤ります。このグラフでは、データの「偏り」を調整して、PreとPostの「山の位置」がどれくらいズレたかを、人間の目で直感的に捉えやすい形に整えています。\nカーネル密度推定 (KDE: Kernel Density Estimation) 【定義】: ヒストグラムに重なっている曲線はカーネル密度推定です。これは、離散的なデータポイントから連続的な確率密度関数を推定する手法であり、ヒストグラムのビン（棒）の切り方に依存せずに、データの分布形状を滑らかに表現します。 【直感】: 点々としたデータの集まりを、「なだらかな山」として描いたものです。山の形を見ることで、「だいたい何秒くらいのユーザーが一番多いのか」や「分布のばらつき（山の幅）」を一目で比較できるようになります。\n\n\n\n結論としての意思決定支援\nこのプロットから得られるビジネス上の洞察は、「全ページ合計の平均値では改善しているように見えても、最も売上に直結する Checkout ページで致命的な遅延が発生している」というリスクの可視化です。\n\n\n非中心化による階層ベイズモデル\nN=20のような小規模データで階層モデル（特に分散パラメータ \\(\\sigma\\) が小さい場合）を推定すると、MCMCサンプラーが「漏斗（Funnel）のような形状」の確率分布を探索できず、Divergences（発散） というエラーが頻発することがあります。 これはベイズ推論の信頼性を損ってしまう為、回避する為に、変数の依存関係を数式上で切り離す 「非中心化」 テクニックを用います。 - 中心化（Centered）: \\(\\beta \\sim \\text{Normal}(\\mu, \\sigma)\\) - \\(\\beta\\) の値が決まる際、\\(\\mu\\) と \\(\\sigma\\) に直接依存する。 - 非中心化（Non-centered）: \\(z \\sim \\text{Normal}(0, 1)\\), \\(\\beta = \\mu + z \\cdot \\sigma\\) - \\(z\\) は標準正規分布から独立に生成され、あとでスケーリングされる。これによりサンプラーがスムーズに空間を移動できる。\n\nidx_page, pages = pd.factorize(df[\"page\"])\nidx_group, groups = pd.factorize(df[\"group\"])\n\n# PyMC用 Coords (座標) 定義\ncoords = {\n    \"id_obs\": df.index.values,\n    \"page\": pages,\n    \"group\": groups  # [\"Pre\", \"Post\"]\"\n}\n\n複雑な階層モデルの可読性をあげる為、PyMC における - カテゴリ変数のIndex化 - 【定義】: モデル内部での行列演算を効率化するため、文字列（“Top”, “Checkout”等）を整数インデックス（0, 1, …）に変換する処理です。これにより、各観測データがどのグループ（階層）に属するかを、数式内でポインタのように参照できるようになります。 - 【直感】: 「住所録」に名前でアクセスするのではなく、「出席番号」を割り振る作業です。「出席番号1番のLCPはこれ」と番号で管理することで、計算機が迷わず高速にデータを処理できるようになります。 - Coords(座標)の定義 - 【定義】: 確率変数の各次元（Dimension）に対して、人間が理解できるラベルを付与する仕組みです。PyMC（内部的にはxarrayを使用）において、多次元配列の各軸が何を意味しているのか（どのページか、どのグループか）を明示的に宣言します。 - 【直感】: グラフの「軸（ラベル）」を定義することです。ただの「4行2列の数字の塊」に、「縦軸はページ名（Top等）」「横軸は施策の前後（Pre/Post）」という名前を付けることで、後で結果を見たときに「どの数字がCheckoutページのPostの結果か」を一目でわかるようにします。\nというプロセスを実施します。\n\nなぜこれらが必要なのか？（主な3つの目的）\n\n高次元データの整合性確保 (Error Prevention) 階層モデルでは、「ページ(4) × グループ(2)」のようにパラメータが多次元になります。 Coordsを定義しておくと、PyMCが自動的に「4×2の行列」と「観測データ（N=160）」を正しくマッピングしてくれます。これにより、行列のサイズが合わないといった実行時エラーを未然に防ぐことができます。\n意味のある事後分布の解析 (Labeling) MCMCによるサンプリング結果（事後分布）を解析する際、Coordsが定義されていると、ArviZなどのツールを使って以下のように直感的にアクセスできます。 trace.posterior[“mu_cell”].sel(page=“Checkout”, group=“Post”) もしCoordsがないと、trace.posterior[“mu_cell”][:, :, 3, 1] のように「マジックナンバー（3や1が何を指すか不明な状態）」で指定しなければならず、ミスや混乱の元になります。\n非中心化実装の柔軟性 今回のモデルで採用している「非中心化（Non-centered）」モデルでは、標準正規分布からサンプリングした値にズレ（）を掛け合わせる操作を行います。 Coordsがあると、この「ズレ」をどの次元に対して適用するのかを dims=(“page”, “group”) のように名前で指定でき、モデルの構造が非常に読みやすくなります。\n\nこのように、Index化とCoordsの定義は、 「計算機のための効率化」と「人間のための可読性・解析性」 を両立させるための非常に重要なベストプラクティスです。これを行うことで、将来的にページ数が増えたり、新しいセグメント（デバイス別など）を追加したりする場合も、モデルの拡張が容易になります\n\nwith pm.Model(coords=coords) as model:\n    # --- Data Containers ---\n    _idx_page  = pm.Data(\"idx_page\", idx_page, dims=\"id_obs\")\n    _idx_group = pm.Data(\"idx_group\", idx_group, dims=\"id_obs\")\n    _obs_lcp   = pm.Data(\"obs_lcp\", df[\"lcp\"].values, dims=(\"id_obs\"))\n\n    # --- Hierarchical Priors (Non-centered Parameterization)\n\n    # 1. Global Intercept (全体の基準値)\n    mu_global = pm.Normal(\"mu_global\", mu=7.5, sigma=1.0, dims=\"group\")\n\n    # 2. Page-level Deviations (Page ごとのクせ)\n    # sigma_page: ページ間のばらつきの大きさ\n    sigma_page = pm.HalfNormal(\"sigma_page\", sigma=0.5)\n\n    # offset_page_z: 標準正規分布に従う「ズレの素」（非中心化の肝）\n    # shape=(4page, 2group) -&gt; 各ページ・各グループごとに固有の偏差を持つ\n    offset_page_z = pm.Normal(\"offset_page_z\", mu=0.0, sigma=1.0, dims=(\"page\", \"group\"))\n\n    # Deterministic で実際に偏差に変換: beta = mu + z * sigma\n    mu_page = pm.Deterministic(\n        \"mu_page\",\n        mu_global + offset_page_z * sigma_page,  # broadcasting\n        dims=(\"page\", \"group\")\n    )\n\n    # --- Likelihood ---\n    sigma_obs = pm.HalfNormal(\"sigma_obs\", sigma=0.5)\n\n    # 予測値の構築\n    # mu_page は (page, group) の２次元配列なので、Index で参照\n    mu_LCP = mu_page[_idx_page, _idx_group]\n\n    lcp = pm.Lognormal(\"lcp\", mu=mu_LCP, sigma=sigma_obs, observed=_obs_lcp, dims=(\"id_obs\"))\n\n\npm.model_to_graphviz(model)\n\n\n\n\n\n\n\n\n\n\n\n非中心化による階層ベイズモデル\nこの構造により、モデルは「情報の借用（Shrinkage）」を適切に行いつつ、小規模データでもサンプリングが収束しやすい（発散しにくい）堅牢なものになっています。 - 【直感】: 個性の強さ」と「個々のズレ」を分ける 「ページごとの個性がどれくらい強いか（sigma_page）」というボリュームのつまみと、 「各ページが標準からどの方向にズレているか（offset_page_z）」という方向のつまみを分けたイメージです。 これにより、データが少ないCheckoutページなどの推定値が、全体の平均（mu_global）に向かって適切に引き寄せられ、極端な外れ値に振り回されるのを防ぎます。\n\n# --- 推論 ---\nwith model:\n    trace = pm.sample(draws=2000, tune=1000, target_accept=0.95, random_seed=RANDOM_SEED)\n\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [mu_global, sigma_page, offset_page_z, sigma_obs]\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 20 seconds.\n\n\n\n# 推論結果\naz.plot_trace(trace, compact=False, var_names=[\"mu_global\", \"sigma_page\", \"offset_page_z\"])\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n1. トレースプロットの形状（Fuzzy Caterpillar）\n見た目の特徴: 各チェーン（異なる色の線）が互いにしっかりと混ざり合い、特定の傾向（右肩上がりや下がり）を持たず、一定の範囲を細かく上下に振動しています。\n解釈: これがいわゆる「毛虫（Fuzzy Caterpillar）」のような状態であり、サンプラーが事後分布の全体を効率よく探索できていることを示します。 特定の場所で停滞したり、チェーンごとに大きく値が離れたりしていないため、良好な収束のサインです。\n\naz.summary(trace, var_names=[\"mu_global\", \"sigma_page\", \"offset_page_z\"])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu_global[pre]\n8.010\n0.082\n7.854\n8.166\n0.001\n0.002\n3190.0\n3060.0\n1.0\n\n\nmu_global[post]\n8.000\n0.082\n7.841\n8.157\n0.001\n0.002\n3341.0\n3321.0\n1.0\n\n\nsigma_page\n0.130\n0.070\n0.007\n0.251\n0.002\n0.002\n1738.0\n2415.0\n1.0\n\n\noffset_page_z[Top, pre]\n-0.082\n0.709\n-1.399\n1.297\n0.010\n0.008\n5245.0\n5857.0\n1.0\n\n\noffset_page_z[Top, post]\n-0.701\n0.740\n-2.079\n0.713\n0.010\n0.009\n4986.0\n5565.0\n1.0\n\n\noffset_page_z[Detail, pre]\n-0.130\n0.724\n-1.475\n1.238\n0.010\n0.009\n4953.0\n5164.0\n1.0\n\n\noffset_page_z[Detail, post]\n-0.922\n0.743\n-2.343\n0.441\n0.011\n0.008\n4651.0\n5738.0\n1.0\n\n\noffset_page_z[Contract, pre]\n0.038\n0.710\n-1.280\n1.388\n0.010\n0.008\n5021.0\n5358.0\n1.0\n\n\noffset_page_z[Contract, post]\n0.689\n0.728\n-0.703\n2.014\n0.011\n0.009\n4769.0\n5210.0\n1.0\n\n\noffset_page_z[Checkout, pre]\n0.289\n0.716\n-1.009\n1.689\n0.010\n0.009\n4986.0\n5239.0\n1.0\n\n\noffset_page_z[Checkout, post]\n0.981\n0.754\n-0.393\n2.427\n0.011\n0.010\n4460.0\n4933.0\n1.0\n\n\n\n\n\n\n\n\n\n2. \\(\\hat{R}\\) (R-hat) 指標\n数値 : すべてのパラメータにおいて、値が 1.00 になっています。\n解釈 : \\(\\hat{R}\\) は「チェーン間のばらつき」と「チェーン内のばらつき」を比較する指標です。 一般に 1.1 未満（厳密には 1.05 未満）であれば収束したとみなされます。 今回の結果は、全て 1.00 に極めて近いため、複数の独立した試行（チェーン）がすべて同じ統計的結論に達していることを意味します。\n\n\n3. 効サンプルサイズ (ESS: Effective Sample Size)\ness_bulk および ess_tail カラムを確認してください。\n数値 : 今回の設定（draws=2000, chains=4 の場合、計 8000 サンプル）に対して、十分な大きさ（数百〜数千以上）が確保されています。\n解釈 : MCMC のサンプルは前後の値に相関があるため、実際のサンプル数よりも「有効な（独立した）情報量」は少なくなります。 ESS が大きいことは、自己相関が低く、事後分布の平均や裾（テイル）の推定が安定していることを示します。\n1, 2, 3, より MCMC は、非常に良好に収束しており、推論結果は十分に信頼できる状態と判断。\n\n# --- Shrinkage (情報の借用)の可視化 ---\n\n# 1. Source-data の平均（MEL: 最尤推定に相当）\nmeans_raw_log = {}\nfor page in pages:\n    for group in groups:\n        mask = (df[\"page\"] == page) & (df[\"group\"] == group)\n        means_raw_log[(page, group)] = np.log(df.loc[mask, \"lcp\"]).mean()\n\n# 2. 事後分布の平均（Bayes 推定値）\nmu_posterior_page = trace.posterior[\"mu_page\"].mean(dim=[\"chain\", \"draw\"])\n\n# 3. 全体の平均 (Grand Mean)\nmu_posterior_global = trace.posterior[\"mu_global\"].mean(dim=\n                                                        [\"chain\", \"draw\"])\n\n# --- 可視化 ---\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\ncolors = plt.cm.tab10.colors  # Color-Palet\n\nfor i, group in enumerate(groups):\n    ax = axes[i]\n\n    # 各ページのポイント\n    for j, page in enumerate(pages):\n        # Source-data の平均（x軸） - Dict から取得\n        mean_raw = means_raw_log[(page, group)]\n\n        # Bayes推定の事後平均（y軸）\n        mean_bayes = float(mu_posterior_page.sel(page=page, group=group).values)\n\n        # Plot\n        ax.scatter(mean_raw, mean_bayes, s=150, color=colors[j], zorder=3)\n        ax.annotate(page, (mean_raw, mean_bayes), textcoords=\"offset points\", xytext=(8, 5), fontsize=11)\n\n    # Grand Mean (全体平均)の水平線\n    mean_grand = float(mu_posterior_global.sel(group=group).values)\n    ax.axhline(mean_grand, color=\"red\", linestyle=\"--\", alpha=0.7, label=f\"Grand Mean ({np.exp(mean_grand):.0f}ms\")\n\n    # 45度線（Shrinkage なしの場合）\n    x_all = [means_raw_log[(p, group)] for p in pages]\n    y_all = [float(mu_posterior_page.sel(page=p, group=group).values) for p in pages]\n    val_min = min(x_all + y_all) - 0.1\n    val_max = max(x_all + y_all) + 0.1\n\n    ax.plot([val_min, val_max], [val_min, val_max], color=\"gray\", linestyle=\":\", alpha=0.5, label=\"No Shrinkage (45°)\")\n    ax.set_xlim(val_min, val_max)\n    ax.set_ylim(val_min, val_max)\n\n    ax.set_xlabel(\"Raw Data Mean (log scale)\", fontsize=12)\n    ax.set_ylabel(\"Bayesian Posterior Mean (log scale)\", fontsize=12)\n    ax.set_title(f\"Shrinkage Plot: {group}\", fontsize=14)\n    ax.legend(loc=\"lower right\")\n    ax.grid(True, alpha=0.3)\n    ax.set_aspect(\"equal\", adjustable=\"box\")\n\nplt.suptitle(\"Shrinkage (情報の借用) の可視化\", fontsize=16)\nplt.tight_layout()\nplt.show()\n\n/tmp/ipykernel_13667/2364994097.py:58: UserWarning: Glyph 24773 (\\N{CJK UNIFIED IDEOGRAPH-60C5}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/tmp/ipykernel_13667/2364994097.py:58: UserWarning: Glyph 22577 (\\N{CJK UNIFIED IDEOGRAPH-5831}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/tmp/ipykernel_13667/2364994097.py:58: UserWarning: Glyph 12398 (\\N{HIRAGANA LETTER NO}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/tmp/ipykernel_13667/2364994097.py:58: UserWarning: Glyph 20511 (\\N{CJK UNIFIED IDEOGRAPH-501F}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/tmp/ipykernel_13667/2364994097.py:58: UserWarning: Glyph 29992 (\\N{CJK UNIFIED IDEOGRAPH-7528}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/tmp/ipykernel_13667/2364994097.py:58: UserWarning: Glyph 21487 (\\N{CJK UNIFIED IDEOGRAPH-53EF}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/tmp/ipykernel_13667/2364994097.py:58: UserWarning: Glyph 35222 (\\N{CJK UNIFIED IDEOGRAPH-8996}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/tmp/ipykernel_13667/2364994097.py:58: UserWarning: Glyph 21270 (\\N{CJK UNIFIED IDEOGRAPH-5316}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/home/peta/petaLab/bayesian-iroha/.venv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 24773 (\\N{CJK UNIFIED IDEOGRAPH-60C5}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n/home/peta/petaLab/bayesian-iroha/.venv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 22577 (\\N{CJK UNIFIED IDEOGRAPH-5831}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n/home/peta/petaLab/bayesian-iroha/.venv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 12398 (\\N{HIRAGANA LETTER NO}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n/home/peta/petaLab/bayesian-iroha/.venv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 20511 (\\N{CJK UNIFIED IDEOGRAPH-501F}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n/home/peta/petaLab/bayesian-iroha/.venv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 29992 (\\N{CJK UNIFIED IDEOGRAPH-7528}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n/home/peta/petaLab/bayesian-iroha/.venv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 21487 (\\N{CJK UNIFIED IDEOGRAPH-53EF}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n/home/peta/petaLab/bayesian-iroha/.venv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 35222 (\\N{CJK UNIFIED IDEOGRAPH-8996}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n/home/peta/petaLab/bayesian-iroha/.venv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 21270 (\\N{CJK UNIFIED IDEOGRAPH-5316}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n\n\n\n\n\n\n\n\n\n\n\nPlot の構成要素\n\nX軸 (Raw Data Mean) : 生データから計算した各ページの平均 LCP（対数スケール）。最尤推定（MLE）に相当します。\nY軸 (Bayesian Posterior Mean) : 階層ベイズモデルによる推定値（事後平均）\n各点（Top, Detail, Contract, Checkout） : 各ページの推定値を表すプロット\n赤い破線（Grand Mean） : 全ページの全体平均（階層モデルの「親」の推定値）\n灰色の点線（45度線） : Shrinkage がない場合の基準線（生データ = ベイズ推定値）\n\n\n\n解釈\n今回の N=20 という小規模データでは： すべてのページで若干の Shrinkage が発生しているはずです（点が45度線から少し離れている）。 - Grand Mean に近いページ（例: Contract）は、あまり Shrinkage の影響を受けません（もともと全体平均に近いため）。 - Grand Mean から離れたページ（例: Top や Checkout）は、より強く全体平均に引き寄せられます。\nCheckout ページのデータは N=20 しかないが、階層モデルが他のページの傾向を借用して推定値を安定させている様子です。 その結果、生データよりも信頼できる推定値が得られていると判断できます。\n\n\n解釈のポイント\n\n\n45度線との位置関係\n\n\n点が45度線上にある場合: Shrinkage なし。生データの平均がそのまま推定値として採用されています。\n点が45度線から離れて赤線（Grand Mean）に近づいている場合: Shrinkage が働いています。モデルが「このページのデータだけでは不確実なので、他のページの情報を借りて調整しよう」と判断しています。\n\n\n\n\nShrinkage が起こる理由 階層ベイズモデルでは、データが少ない or ばらつきが大きいグループほど、全体平均に向かって「引き寄せられる」傾向があります。\n\n\n\n\n以下のような効果をもたらします：\n\n\nデータが少ない : 外れ値に振り回されるのを防ぐ\nばらつきが大きい : 過度に極端な推定を避ける\nデータが十分にある : 生データをほぼそのまま信頼\n\n\n\n# Shrinkage の強さを数値化\nprint(\"--- Shrinkage Analysis ---\")\nprint(f\"{'Page':&lt;12} {'Group':&lt;6} {'Raw (ms)':&lt;12} {'Bayes (ms)':&lt;12} {'Shrinkage %':&lt;12}\")\nprint(\"-\" * 60)\n\nfor page in pages:\n    for group in groups:\n        raw = means_raw_log[(page, group)]\n        bayes = float(mu_posterior_page.sel(page=page, group=group).values)\n        grand = float(mu_posterior_global.sel(group=group).values)\n\n        # Shrinkage率: Source-data から全体平均にどれだけ引き寄せられたか\n        if abs(raw - grand) &gt; 0.001:\n            pct_shrinkage = (raw - bayes) / (raw - grand) * 100\n        else:\n            pct_shrinkage = 0.0\n\n        # 実空間(ms)に変換して表示\n        print(f\"{page:&lt;12} {group:&lt;6} {np.exp(raw):&lt;12.0f} {np.exp(bayes):&lt;12.0f} {pct_shrinkage:&lt;12.1f}%\")\n\n--- Shrinkage Analysis ---\nPage         Group  Raw (ms)     Bayes (ms)   Shrinkage % \n------------------------------------------------------------\nTop          pre    2961         2982         41.9        %\nTop          post   2612         2736         35.1        %\nDetail       pre    2937         2966         39.5        %\nDetail       post   2505         2666         35.8        %\nContract     pre    3038         3029         32.5        %\nContract     post   3396         3246         34.6        %\nCheckout     pre    3176         3121         32.9        %\nCheckout     post   3590         3362         35.2        %\n\n\n\n\n\nROPE 判定（実質的等価姓の確認）\nROPE定義 : 「変化が ±50ms 以内であれば、User は気づかない」と定義する。\n\n# 事後分布の抽出と Data 整形\nposterior = trace.posterior\n\n# mu_page: (chain, draw, page, group) -&gt; (samples, page, group)\n# stack chain and draw\nmu_samples = posterior[\"mu_page\"].stack(sample=(\"chain\", \"draw\")).values.transpose(2, 0, 1)\n\n# 対数空間から実空間(ms)へ\nsamples_lcp_ms = np.exp(mu_samples)\n# shape: (samples, 4_pages, 2_groups) -&gt; 0:Pre, 1:Post\n\n# 改善量 (Pre - Post)\nms_diff = samples_lcp_ms[:, :, 0] - samples_lcp_ms[:, :, 1]\n# shape: (samples, 4_pages)\n\n\n# --- ROPE Analysis ---\nROPE_RANGE = [-100, 100]  # ±100ms は誤差とみなす\n\nprint(\"--- ROPE Analysis (Probability of Practical Effect)---\")\nfor i, page in enumerate(pages):\n    # ROPE内に入っている確立\n    prob_in_rope = np.mean((ms_diff[:, i] &gt; ROPE_RANGE[0]) & (ms_diff[:, i] &lt; ROPE_RANGE[1]))\n\n    # ROPE より改善している (&gt;500ms) 確率\n    prob_better = np.mean(ms_diff[:, i] &gt;= ROPE_RANGE[1])\n\n    # ROPE より悪化している (&lt;-500ms) 確率\n    prob_worse = np.mean(ms_diff[:, i] &lt;= ROPE_RANGE[0])\n\n    print(f\"Page: {page}\")\n    print(f\"    Mean Diff: {ms_diff[:, i].mean():.1f} ms\")\n    print(f\"    Prob Better (&gt;{ROPE_RANGE[1]}ms):  {prob_better * 100:.1f}%\")\n    print(f\"    Prob Worse: (&lt;{ROPE_RANGE[0]}ms): {prob_worse * 100:.1f}%\")\n    print(f\"    Prob Equiv  (In ROPE): {prob_in_rope * 100:.1f}%\")\n    print(\"-\" * 30)\n\n--- ROPE Analysis (Probability of Practical Effect)---\nPage: Top\n    Mean Diff: 245.6 ms\n    Prob Better (&gt;100ms):  68.9%\n    Prob Worse: (&lt;-100ms): 10.5%\n    Prob Equiv  (In ROPE): 20.5%\n------------------------------\nPage: Detail\n    Mean Diff: 299.9 ms\n    Prob Better (&gt;100ms):  75.8%\n    Prob Worse: (&lt;-100ms): 7.0%\n    Prob Equiv  (In ROPE): 17.2%\n------------------------------\nPage: Contract\n    Mean Diff: -218.6 ms\n    Prob Better (&gt;100ms):  14.9%\n    Prob Worse: (&lt;-100ms): 64.3%\n    Prob Equiv  (In ROPE): 20.8%\n------------------------------\nPage: Checkout\n    Mean Diff: -243.8 ms\n    Prob Better (&gt;100ms):  14.2%\n    Prob Worse: (&lt;-100ms): 65.8%\n    Prob Equiv  (In ROPE): 20.0%\n------------------------------\n\n\n\n# --- 可視化: 事後分布の HDI と ROPE の重なり具合 ---\nHDI_PROB = 0.94  # 94% HDI\n\n# --- 可視化 ---\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\naxes_flat = axes.flatten()\n\nfor i, page in enumerate(pages):\n    ax = axes_flat[i]\n    data_page = ms_diff[:, i]  # 各ページの改善量サンプル (shape: 8000,)\n\n    # 1. 事後分布の Histogram / KDE\n    az.plot_kde(data_page, ax=ax, plot_kwargs={\"color\": \"mediumpurple\", \"linewidth\": 2}, fill_kwargs={\"alpha\": 0.4})\n\n    # 2. HDI (94%) を計算してプロット\n    hdi = az.hdi(data_page, hdi_prob=HDI_PROB)\n    ax.axvline(hdi[0], color=\"mediumpurple\", linestyle=\"--\", linewidth=1.5, label=f\"{HDI_PROB * 100:.0f}% HDI\")\n    ax.axvline(hdi[1], color=\"mediumpurple\", linestyle=\"--\", linewidth=1.5)\n    # HDI範囲の塗りつぶし（Option）\n    ax.axvspan(hdi[0], hdi[1], alpha=0.1, color=\"mediumpurple\")\n\n    # 3. ROPE を塗りつぶしてプロット\n    ax.axvspan(ROPE_RANGE[0], ROPE_RANGE[1], alpha=0.2, color=\"orange\",\n               label=f\"ROPE ({ROPE_RANGE[0]} to {ROPE_RANGE[1]} ms)\")\n\n    # 4. 参照戦（ゼロ）\n    ax.axvline(0, color=\"black\", linestyle=\":\", linewidth=1, label=\"No Effect (0)\")\n\n    # 5. タイトルと判定ラベル\n    mean_diff = np.mean(data_page)\n\n    # 判定ロジック\n    if hdi[0] &gt; ROPE_RANGE[1]:\n        verdict = \"明確な改善\"\n        verdict_color = \"seagreen\"\n    elif hdi[1] &lt; ROPE_RANGE[0]:\n        verdict = \"明確な悪化\"\n        verdict_color = \"indianred\"\n    elif hdi[0] &gt; ROPE_RANGE[0] and hdi[1] &lt; ROPE_RANGE[1]:\n        verdict = \"実質的に等価\"\n        verdict_color = \"slategray\"\n    else:\n        verdict = \"判断保留\"\n        verdict_color = \"goldenrod\"\n\n    ax.set_title(f\"{page} Page\\nMean: {mean_diff:.0f} ms | {verdict}\", fontsize=12, color=verdict_color,\n                 fontweight=\"bold\")\n    ax.set_xlabel(\"LCP Change (Pre - Post) [ms]\")\n    ax.set_ylabel(\"Density\")\n    ax.legend(loc=\"upper right\", fontsize=8)\n    ax.grid(True, alpha=0.3)\n\nplt.suptitle(\"ROPE Analysis: HDI vs. ROPE Overlap\", fontsize=16, fontweight=\"bold\")\nplt.tight_layout()\nplt.show()\n\n/tmp/ipykernel_13667/1007172029.py:54: UserWarning: Glyph 21028 (\\N{CJK UNIFIED IDEOGRAPH-5224}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/tmp/ipykernel_13667/1007172029.py:54: UserWarning: Glyph 26029 (\\N{CJK UNIFIED IDEOGRAPH-65AD}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/tmp/ipykernel_13667/1007172029.py:54: UserWarning: Glyph 20445 (\\N{CJK UNIFIED IDEOGRAPH-4FDD}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/tmp/ipykernel_13667/1007172029.py:54: UserWarning: Glyph 30041 (\\N{CJK UNIFIED IDEOGRAPH-7559}) missing from font(s) DejaVu Sans.\n  plt.tight_layout()\n/home/peta/petaLab/bayesian-iroha/.venv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 21028 (\\N{CJK UNIFIED IDEOGRAPH-5224}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n/home/peta/petaLab/bayesian-iroha/.venv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 26029 (\\N{CJK UNIFIED IDEOGRAPH-65AD}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n/home/peta/petaLab/bayesian-iroha/.venv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 20445 (\\N{CJK UNIFIED IDEOGRAPH-4FDD}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n/home/peta/petaLab/bayesian-iroha/.venv/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 30041 (\\N{CJK UNIFIED IDEOGRAPH-7559}) missing from font(s) DejaVu Sans.\n  fig.canvas.print_figure(bytes_io, **kw)\n\n\n\n\n\n\n\n\n\n\nROPE 分析結果の解釈\n\nROPE の意味 ROPE（Region of Practical Equivalence）は、実際の業務において差異が顕著に現れる範囲を指します。 この範囲内で変化が認められるかどうかは、ビジネスのコンテキストや User の体験に大きく左右されます。\n\n\n分析結果の解釈\n今回の分析では、「±100ms以内の変化は、ユーザーにとって体感できない（実質的に同等）」という閾値を設定しました。 これは、人間の知覚限界（JND: Just Noticeable Difference）を考慮した、実務的な「ノイズフィルター」として機能します。 Googleの「RAILモデル」においても、100ms以内の応答はユーザーに「即座」に感じさせると定義されています。 そのため、100ms以下の変化は「実質的に同じ（Practical Equivalence）」とみなす考え方が合理的です。\n\n\n\n事後分布の HDI が ROPE とどの程度重なっているか可視化\n\n\n3つの判定結果が一目でわかる HDIとROPEの重なり方によって、以下の3つの結論を視覚的に即座に判断できます。\n\n\n\n\n\n\n\n\n\n\nHDIとROPEの関係\n判定\n図のイメージ\n\n\n\n\nHDI全体がROPEの外側（右）\n✅ 明確な改善\n[—ROPE—]…..[===HDI===]\n\n\nHDI全体がROPEの外側（左）\n❌ 明確な悪化\n[===HDI===]…..[—ROPE—]\n\n\nHDI全体がROPEの内側\n➖ 実質的に等価（変化なし）\n[–[=HDI=]–] (ROPE内にHDI)\n\n\nHDIがROPEと部分的に重なる\n⚠️ 判断保留（データ不足）\n[—RO[==HDI==]PE—]\n\n\n\n\n\n不確実性の大きさが伝わる\n\n\nHDIが狭い: 推定に自信がある。\nHDIが広い: データが少なく、推定がまだ曖昧。\n\nHDIの「幅」は、推定の不確実性（データの少なさ、ばらつき）を反映します。 これにより、「改善しているが、まだ確証はない」といったニュアンスを経営層に伝えることができます。\n\n\n\nROPE分析結果の解釈\n可視化の読み方（凡例）\n\n\n\n\n\n\n\n要素\n意味\n\n\n\n\n紫の曲線・網掛け\n改善量（Pre - Post）の事後分布と94% HDI\n\n\n黄色の網掛け\nROPE（±100ms）：この範囲内の変化は「体感できない」とみなす\n\n\n灰色の点線\nゼロライン（変化なし）\n\n\n\n\n各ページの判定結果\n\nTop ページ：✅ 明確な改善 観察結果:\n\n事後分布（紫）が、ROPE（黄色）の右側に完全に位置している\n94% HDI の下限が ROPE の上限（+100ms）を超えている\n平均改善量は約 +500ms 前後\n\n解釈: TopページのLCPは、施策後にユーザーが確実に体感できるレベルで高速化しました。 94%の確信度で「100ms以上の改善がある」と言えます。\n【直感】: 「速くなったかも？」ではなく、「間違いなく速くなった」と自信を持って言える状態です。\nDetail ページ：✅ 明確な改善（または改善傾向） 観察結果:\n\n事後分布（紫）の大部分が ROPE の右側に位置\n94% HDI がほぼ ROPE 外にある（わずかに重なる可能性あり）\n平均改善量は約 +200ms 前後\n\n解釈: Detailページも体感可能な改善が認められます。 Topほどの確信度ではないものの、80〜95%の確率で体感できる改善があります。\n【直感】: 「おそらく速くなった」と言える状態。追加データがあれば確信が強まります。\nContract ページ：➖ 実質的に等価（変化なし） 観察結果:\n\n事後分布（紫）が ROPE（黄色）の内部にほぼ収まっている\n94% HDI の両端が ROPE 内に含まれている\n平均改善量は約 ±0〜50ms 程度\n\n解釈: Contractページは、統計的にわずかな差があったとしても、ユーザーにとっては「変わっていない」と判断できます。 この施策による影響は実質ゼロです。\n【直感】: 「良くも悪くもなっていない」中立の状態。このページへの追加対応は不要です。\nCheckout ページ：❌ 明確な悪化（Blocker） 観察結果:\n\n事後分布（紫）が、ROPE（黄色）の左側に完全に位置している\n94% HDI の上限が ROPE の下限（-100ms）を下回っている\n平均悪化量は約 -1000ms（約1秒） 前後\n\n解釈: Checkoutページは、施策後にユーザーが確実に体感できるレベルで遅延しています。 94%の確信度で「100ms以上の悪化がある」と言え、実際には約1秒もの遅延が発生しています。\n【直感】: 「遅くなったかも？」ではなく、「間違いなく遅くなった」という、リリースをブロックすべき明確なシグナルです。\n\n\n\n結果サマリー\n\n\n\nページ\nHDIとROPEの関係\n判定\nアクション\n\n\n\n\nTop\nHDI全体がROPE右側\n✅ 明確な改善\nリリース推奨\n\n\nDetail\nHDIの大部分がROPE右側\n✅ 改善傾向\nリリース推奨\n\n\nContract\nHDI全体がROPE内\n➖ 等価（変化なし）\n対応不要\n\n\nCheckout\nHDI全体がROPE左側\n❌ 明確な悪化\nブロッカー\n\n\n\n\n\n意思決定への示唆\nこの可視化から導かれる結論は以下の通りです。 ROPE判定の総合結論: 今回の施策は、Top・Detailページにおいてユーザー体感レベルの明確な改善をもたらした一方、 Checkoutページにおいて約1秒の致命的な遅延を引き起こしている。Checkoutページの悪化は、94% HDI が ROPE を完全に下回っており、 統計的にも実務的にも「許容不可」 と判断される。\n\n\n\n\nROI-シミュレーション (経済的判断)\n\n# --- Business Parameters ---\nn_samples = ms_diff.shape[0]  # サンプル数を取得\n\n# 基本パラメータ\nPV_MONTHLY = np.array([1_000_000, 100_000, 10_000, 1_000])\nAOV = 5_000\nCOST_IMPLEMENTATION = 100_000\n\n# 感度(Sensitivity) を (N_sample, 4) の行列として生成\nmatrix_sensitivity = np.tile([0.0001, 0.0005, 0.0050, 0.0000], (n_samples, 1))  # 固定値で初期化\n\n# 【重要】Checkout (Index 3) の感度を「幅のある分布」として生成\n# \"0.04〜0.06の間でばらつく\" -&gt; 一様分布 (Uniform Distribution) を採用\n# ※ より確信がある場合は正規分布 rng.normal(loc=0.05, scale=0.005, size=n_samples) なども可\nsensitivity_checkout_dist = rng.uniform(low=0.04, high=0.06, size=n_samples)\nmatrix_sensitivity[:, 3] = sensitivity_checkout_dist\n\n# 1ms あたりの価値も分布になる（N_samples, 4）\nvalue_per_ms_dist = matrix_sensitivity * PV_MONTHLY * AOV\n\n\nビジネスパラメータの定義：固定値と不確実性の統合\nROIシミュレーションを行うために、ビジネス上の「固定パラメータ」と、リスクを考慮するための「確率的パラメータ（不確実性）」をそれぞれ定義します。\n\n1. 固定ビジネスパラメータ（Business Constants）\nこれらは、アクセス解析や財務データから明確に値が決まっているパラメータです。\n\nPV_MONTHLY（月間ページビュー）\n\n【定義】: 各ページタイプの1ヶ月あたりのアクセス数です。\n\nTop (1,000,000): 圧倒的にアクセスが多い場所です。\nCheckout (1,000): 全体の0.1%しか到達しない、貴重な購入直前のステップです。\n\n【直感】: 「影響が及ぶ人数」です。Topページは改善の幅が小さくても、人数が多いため塵も積もれば山となります。逆にCheckoutページは人数が少ないため、ここ単体の平均値だけを見ていても全体の数字は動きにくいという性質があります。\n\nAOV（平均客単価）\n\n【定義】: Average Order Valueの略で、1回の購入あたりの平均売上金額（ここでは5,000円）です。\n【直感】: 「1回の成功の重み」です。CVRが上がった結果、1件の成約が増えるごとにいくら売上が増えるのかを計算するために使用します。\n\nCOST_IMPLEMENTATION（実装コスト）\n\n【定義】: パフォーマンス改善施策（エンジニアの工数やツール費用など）にかかった一時的な費用です（ここでは10万円）。\n【直感】: 「この施策にかかった投資額」です。施策による売上増がこのコストを上回らなければ、ビジネスとしては「赤字」と判断されます。\n\n\n\n\n\n2. 確率的パラメータ（Probabilistic Parameters for Sensitivity Analysis）\nここでは「売上感度」を固定値ではなく確率分布として扱うことで、前提条件がズレていた場合のリスクを織り込みます。\n\nsensitivity_checkout_dist（Checkoutページの感度分布）\n\n【定義】: Checkoutページの売上感度を、固定値ではなく 一様分布 Uniform(0.04, 0.06) に従う確率変数として定義します。\n【直感】: 「感度はだいたい0.05%くらいだが、最悪0.06%（敏感）、良くても0.04%（鈍感）の範囲のどこかにある」という、分析者の “迷い” や “想定の幅” をそのままモデルに反映させています。\n\nmatrix_sensitivity（感度行列）\n\n【定義】: MCMCのサンプル数に対応した (N_samples, 4) の行列です。Topページなどは固定値ですが、Checkout列には上記の確率分布（ばらつき）が格納されています。\n【直感】: 「もしもの世界」のカタログです。「ある世界では客が怒りやすく（感度高）、別の世界では寛容（感度低）」といった何千通りものパラレルワールドを表現しています。\n\nvalue_per_ms_dist（確率的な1msの価値）\n\n【定義】: 感度の不確実性を反映した、1msあたりの金銭的価値の分布です。 \\[Value\\_per\\_ms \\sim PV \\times Sensitivity(\\text{分布}) \\times AOV\\]\n【直感】: これまでは「1ms遅れると250円の損失」と決め打ちしていましたが、ここでは「200円〜300円の間のどこか」というように、損失単価自体が揺れ動く幅を持っています。これにより、「感度が高く、かつ速度も遅くなった」という最悪のシナリオ（ワーストケース）を含めた評価が可能になります。\n\n\n\n# --- ROI Calculation with Sensitivity Analysis ---\n\n# ページごとの損益インパクト (円)\n# ms_diff (速度の不確実性) × value_per_ms_dist (ビジネス感度の不確実性)\nimpact_per_page_prob = ms_diff * value_per_ms_dist\n\n# トータルの純利益分布\ntotal_revenue_uplift = np.sum(impact_per_page_prob, axis=1)\nprofit_net_prob = total_revenue_uplift - COST_IMPLEMENTATION\n\n\n# --- Visualization ---\nplt.figure(figsize=(12, 6))\n\n# Plot 01: Total Net Profit (Sensitivity Included)\nplt.subplot(1, 2, 1)\nplt.hist(profit_net_prob, bins=50, alpha=0.7, density=True, label=\"Net Profit Dist\")\nplt.axvline(0, linestyle=\"--\", linewidth=2, color=COLOR_YELLOW, label=\"Break-even\")\nplt.title(\"Total ROI Distribution\\n(w/ Sensitivity Uncertainty)\")\nplt.xlabel(\"Net Profit (JPY)\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nROI分布の可視化：感度の不確実性を含めた純利益シミュレーション\nこのプロットは、今回の施策がもたらす純利益（Net Profit）の確率分布を示しています。\n\nプロットの構成要素\n\n\n\n\n\n\n\n要素\n意味\n\n\n\n\nヒストグラム（青/紫）\nMCMCサンプルから計算された純利益の分布。横軸が利益額（円）、縦軸が確率密度。\n\n\n黄色の破線（Break-even）\n損益分岐点（0円）。この線より右が黒字、左が赤字を意味する。\n\n\n\n\n\n読み取り方\n\n分布の中心（山の位置）: 期待される純利益の「最も起こりやすい値」を示します。\n分布の幅（山の広がり）: 利益予測の不確実性を表します。幅が広いほど「振れ幅が大きい」ことを意味します。\n0円ラインとの重なり: 分布のどの程度が0円より左（赤字領域）にあるかで、赤字リスクを視覚的に把握できます。\n\n\n\n解釈のポイント\n\n分布全体が0より右にある場合: 高い確率で黒字。施策は経済的に成功と判断できます。\n分布が0を跨いでいる場合: 黒字になる可能性も赤字になる可能性もある状態。リスクの定量化が必要です。\n分布全体が0より左にある場合: 高い確率で赤字。施策の見直しが必要です。\n\n\n\n技術的補足\n\n【定義】: 感度の不確実性 (Sensitivity Uncertainty)\n「1msの改善がCVRを何%向上させるか」という売上感度（Sensitivity）自体にも不確実性があります。このシミュレーションでは、感度パラメータにも確率分布を仮定し、LCP改善量の不確実性と同時に考慮しています。これにより、単一の点推定ではなく、より現実的なリスク評価が可能になります。\n\n\n【直感】\n「100ms速くなったら売上が1%上がる」と決め打ちするのではなく、「0.5%〜1.5%くらいの幅で上がるかもしれない」という幅を持たせて計算しています。これにより、「最悪のケースでも黒字か？」「最良のケースでどこまで伸びるか？」といった問いに答えられます。\n\n\n# Plot 2: Checkout Page Impact Only\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 2)\nidx_checkout = list(pages).index(\"Checkout\")\nplt.hist(impact_per_page_prob[:, idx_checkout], bins=50, color=COLOR_RED, alpha=0.7, density=True)\nplt.axvline(0, color=\"black\", linestyle=\"--\", linewidth=2)\nplt.title(\"Checkout Page Imapct Risk\\n(Sensitivity: 0.04~0.06)\")\nplt.xlabel(\"Revenue Change (JPY)\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCheckout ページ売上インパクトリスク分布の可視化\nこのプロットは、Checkout ページ単体が施策によってどれだけの売上影響を受けるかを確率分布として可視化したものです。\n\nプロットの構成要素\n\n\n\n\n\n\n\n要素\n意味\n\n\n\n\nヒストグラム（赤色）\nMCMCサンプルから計算されたCheckoutページの売上変動分布。横軸が収益変動額（円）、縦軸が確率密度。\n\n\n黒い破線（0円ライン）\n損益分岐点。この線より右が収益増、左が収益減（損失）を意味する。\n\n\nタイトルの「Sensitivity: 0.04~0.06」\nCheckoutページの売上感度を固定値ではなく、0.04〜0.06の一様分布として不確実性を織り込んでいることを示す。\n\n\n\n\n\n読み取り方\n\n分布の中心（山の位置）: Checkoutページにおける期待される売上変動額を示します。\n分布の幅（山の広がり）: LCP変動の不確実性と売上感度の不確実性を同時に反映しており、予測の振れ幅を表します。\n0円ラインとの位置関係: 分布全体が0より左（マイナス領域）にあるほど、このページが収益に対してリスク要因であることを示します。\n\n\n\n解釈のポイント\n\n分布が0より完全に左にある場合: Checkoutページは明確な損失源であり、施策全体の黒字を帳消しにする可能性があります。\n分布が0を跨いでいる場合: 損失になる確率と利益になる確率が混在しており、追加検証が必要です。\nタイトルに「Imapct Risk」とある理由: 売上直結のCheckoutページでの遅延は、PVあたりの損失単価が極めて高いため、全体のROIを左右するリスクファクターとして特別に可視化しています。\n\n\n\n技術的補足\n\n【定義】: 感度の確率的モデリング\n通常のROI計算では「1msあたりの売上影響 = 固定値」として計算しますが、このシミュレーションでは Checkout ページの感度を Uniform(0.04, 0.06) の一様分布として定義しています。これにより、「感度が予想より高かった場合」と「低かった場合」の両方のシナリオを同時に評価しています。\n\n\n【直感】\n「1秒遅れると5%離脱」という前提が、実は「4%〜6%の幅のどこかにある」という不確かさを認め、最悪ケースでどれくらいの損失が出るかを可視化したものです。これにより、単なる期待値ではなくリスクの下限（ワーストケース）を意思決定に組み込むことができます。\n\n\n\nビジネス上の示唆\nこのプロットから得られる重要な洞察は、「全体のROIがプラスでも、Checkoutページ単体で見ると大きな損失が発生している可能性がある」という点です。特にECサイトにおいて、決済直前のパフォーマンス劣化は「カゴ落ち」を招き、LTV（顧客生涯価値）の低下やブランド毀損につながる取り返しのつかない損失となるリスクがあります。\n\n# --- 4. 意思決定指標 (Decision Metric) ---\nmean_profit = np.mean(profit_net_prob)\nrate_win = np.mean(profit_net_prob &gt; 0)\n\n# 感度が下振れ(0.04)した場合も含めた、Checkout ページの損失リスク\nrisk_checkout_loss = np.mean(impact_per_page_prob[:, idx_checkout] &lt; -10_000)\n\nprint(\"=== Sensitivity Analysis Result ===\")\nprint(\"Checkout Sensitivity: Uniform(0.04, 0.06)\")\nprint(f\"Expected Net Profit: {mean_profit:,.0f} JPY\")\nprint(f\"Win Rate: (Profit &gt; 0): {rate_win * 100:.1f}%\")\nprint(f\"Checkout Risk (Loss &gt; 10k): {risk_checkout_loss * 100:.1f}%\")\n\n=== Sensitivity Analysis Result ===\nCheckout Sensitivity: Uniform(0.04, 0.06)\nExpected Net Profit: 82,099,757 JPY\nWin Rate: (Profit &gt; 0): 65.1%\nCheckout Risk (Loss &gt; 10k): 77.4%\n\n\n\n\n\n結論と推奨アクション\n\nROI シミュレーション結果サマリー\n\n\n\n\n\n\n\n\n指標\n値\n解釈\n\n\n\n\n期待純利益 (Expected Net Profit)\n約 8,210 万円\n平均的には大幅な黒字が見込める\n\n\n勝率 (Win Rate: Profit &gt; 0)\n65.1%\n約3回に1回は赤字になるリスクあり\n\n\nCheckout 損失リスク (Loss &gt; 1万円)\n77.4%\n⚠️ 極めて高いリスク\n\n\n\n\n\n\n\n分析結果の解釈\n今回の感度分析（Sensitivity: 0.04〜0.06）を含めた ROI シミュレーションにより、以下の重要な事実が判明しました。\n\n✅ 良い点：全体 ROI の期待値はプラス\n\n期待純利益は約 8,200 万円 と、実装コスト（10万円）を大幅に上回る。\nTop ページと Detail ページの改善効果が、金額ベースで大きく貢献している。\n\n\n\n❌ 問題点：Checkout ページが致命的なリスク要因\n\n勝率 65.1% は、一見すると「勝ち越し」に見えるが、約35%の確率で赤字になる。\nCheckout ページ単体で 1万円以上の損失が発生する確率が 77.4% と極めて高い。\nこれは、Checkout ページの約1秒の遅延が、高感度（4〜6%/100ms）と掛け合わさることで、他ページの改善効果を打ち消しうることを意味する。\n\n\n\n\n\n意思決定のロジック\n\n「全体で黒字なら良い」という判断は危険である。\n\nCheckout ページの体験悪化は、今回のモデルに含まれていない以下の 長期的・間接的な損失 を招く可能性がある：\n\nカゴ落ち率の上昇: 決済直前の離脱は、最も機会損失が大きい。\nブランド毀損: 「このサイトは決済が遅い」という口コミ・記憶が残る。\nLTV（顧客生涯価値）の低下: 一度悪い体験をしたユーザーは戻ってこない。\n\n\n\n\n推奨アクション\n\n判定: 条件付きリリース承認（Blocker あり）\n「全体の ROI 期待値は約 8,200 万円のプラスですが、Checkout ページのパフォーマンス劣化が 許容不可（Blocker） です。\n承認条件: 1. Top ページ・Detail ページの改善コードのみをマージ 2. Checkout ページに影響する変更はロールバック（または修正） 3. リリース後、Checkout ページの LCP を 1週間モニタリング し、悪化が見られた場合は即時ロールバック\n部分リリースにより、改善効果の大部分を享受しつつ、致命的なリスクを回避します。」\n\n\n\n\n技術的補足\n\n【定義】: 条件付きリリース (Conditional Release)\n施策の一部のみを本番環境に適用し、リスクの高い部分は除外または修正後に再評価する手法。A/B テストと組み合わせることで、さらにリスクを低減できる。\n\n\n【直感】\n「料理で例えると、全体としては美味しいコース料理でも、1品だけ食中毒のリスクがある食材が入っていたら、その1品だけ外してお客様に出す」という判断です。\n\n\n\n\n次のステップ (Next Step)\n\n\n\n優先度\nアクション\n担当\n\n\n\n\n🔴 高\nCheckout ページの遅延原因を特定・修正\nエンジニア\n\n\n🟡 中\n修正後、N=20 以上のデータで再分析\nデータサイエンティスト\n\n\n🟢 低\n売上感度パラメータの精緻化（実データ検証）\nマーケティング",
    "crumbs": [
      "Web Performance ROI Analysis",
      "エグゼクティブサマリー"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ベイジアンいろは",
    "section": "",
    "text": "小規模データ×階層ベイズでビジネスの勝率を導く「意思決定のいろは」。PyMC v5を用い、単なる有意差検定を超えたROPE/ROI分析によるリスク可視化フレームワークを実装・蓄積するナレッジベース。\n\n\nここには、本プロジェクトで実施した分析レポートを掲載しています。\n\n\n\nプロジェクト概要（README）\n分析実証ログ（Notebook）"
  },
  {
    "objectID": "index.html#概要",
    "href": "index.html#概要",
    "title": "ベイジアンいろは",
    "section": "",
    "text": "小規模データ×階層ベイズでビジネスの勝率を導く「意思決定のいろは」。PyMC v5を用い、単なる有意差検定を超えたROPE/ROI分析によるリスク可視化フレームワークを実装・蓄積するナレッジベース。\n\n\nここには、本プロジェクトで実施した分析レポートを掲載しています。\n\n\n\nプロジェクト概要（README）\n分析実証ログ（Notebook）"
  }
]